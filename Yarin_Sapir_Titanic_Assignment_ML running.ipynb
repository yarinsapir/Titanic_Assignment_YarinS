{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfe2c09",
   "metadata": {},
   "source": [
    "# Supervised Learning Flow – Titanic Survival Prediction  \n",
    "\n",
    "**Students:** Yarin S. (ID: 8635)\n",
    "             Shahaf L. (ID: 8284)\n",
    "\n",
    "### Introduction\n",
    "In this assignment we worked on a complete supervised learning flow using the Titanic dataset.\n",
    "Our goal was to build a model that predicts whether a passenger survived (1) or not (0).\n",
    "\n",
    "### Tools and Assistance Used\n",
    "While preparing this assignment we reviewed some online resources.\n",
    "We also used ChatGPT as a study aid – it helped us understand how cross-validation works,\n",
    "how to evaluate models with the F1 score, and the importance of comparing algorithms such as Logistic Regression and Decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd31ce",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aec6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load train and test data (relative paths for portability)\n",
    "train_df = pd.read_csv(\"titanic_train.csv\")\n",
    "test_df = pd.read_csv(\"titanic_test.csv\")\n",
    "\n",
    "# Display first 5 rows\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f52372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shape and basic information\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b579b5",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# survival distribution\n",
    "sns.countplot(x=\"Survived\", data=train_df)\n",
    "plt.title(\"Survival Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaca937",
   "metadata": {},
   "source": [
    "*This plot shows the overall survival distribution – most passengers did not survive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survival by sex\n",
    "sns.countplot(x=\"Sex\", hue=\"Survived\", data=train_df)\n",
    "plt.title(\"Survival by Sex\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a541177",
   "metadata": {},
   "source": [
    "*This plot shows survival by gender – women had a much higher survival rate than men.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32878442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survival by Pclass\n",
    "sns.countplot(x=\"Pclass\", hue=\"Survived\", data=train_df)\n",
    "plt.title(\"Survival by Passenger Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1e888",
   "metadata": {},
   "source": [
    "*This plot shows survival by passenger class – first class passengers survived more often than those in lower classes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38163d",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79300115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "target = \"Survived\"\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Missing values before:\")\n",
    "print(train_df[features].isnull().sum())\n",
    "\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0])\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].median())\n",
    "test_df[\"Fare\"] = test_df[\"Fare\"].fillna(test_df[\"Fare\"].median())\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(test_df[\"Embarked\"].mode()[0])\n",
    "\n",
    "print(\"\\nMissing values after:\")\n",
    "print(train_df[features].isnull().sum())\n",
    "\n",
    "# One-hot encoding\n",
    "X = pd.get_dummies(train_df[features])\n",
    "y = train_df[target]\n",
    "X_test_final = pd.get_dummies(test_df[features])\n",
    "\n",
    "X, X_test_final = X.align(X_test_final, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "print(\"\\nFeatures after one-hot encoding:\")\n",
    "print(list(X.columns))\n",
    "print(\"\\nFirst 5 rows of processed data:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857ac32",
   "metadata": {},
   "source": [
    "*I decided to keep all the selected features since feature selection did not improve the results. This ensures better model stability.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8710f",
   "metadata": {},
   "source": [
    "## 4. Model Training and Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64004f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"solver\": [\"liblinear\"]\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "for name, mp in models.items():\n",
    "    clf = GridSearchCV(mp[\"model\"], mp[\"params\"], cv=5, scoring=scorer, n_jobs=-1, return_train_score=True)\n",
    "    clf.fit(X, y)\n",
    "    for mean, params in zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params']):\n",
    "        results.append({\"Model\": name, \"Params\": params, \"Mean F1\": mean})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"All experiment results:\")\n",
    "print(results_df)\n",
    "\n",
    "sns.barplot(x=\"Model\", y=\"Mean F1\", data=results_df)\n",
    "plt.title(\"Model Comparison (F1 Score)\")\n",
    "plt.show()\n",
    "\n",
    "best_row = results_df.sort_values(by=\"Mean F1\", ascending=False).iloc[0]\n",
    "print(\"\\nBest configuration:\")\n",
    "print(best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0030815",
   "metadata": {},
   "source": [
    "*I compared Logistic Regression and Decision Tree. The Decision Tree achieved a higher F1 score, so I selected it as the final model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236ae91",
   "metadata": {},
   "source": [
    "## 5. Train Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_row[\"Model\"] == \"LogisticRegression\":\n",
    "    final_model = LogisticRegression(max_iter=1000, **best_row[\"Params\"])\n",
    "else:\n",
    "    final_model = DecisionTreeClassifier(**best_row[\"Params\"])\n",
    "\n",
    "final_model.fit(X, y)\n",
    "print(\"Final model trained with params:\", best_row[\"Params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3258a80",
   "metadata": {},
   "source": [
    "## 6. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214faabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on test set\n",
    "test_predictions = final_model.predict(X_test_final)\n",
    "\n",
    "# Show first predictions\n",
    "print(\"First 10 predictions:\", test_predictions[:10])\n",
    "\n",
    "# Prediction distribution\n",
    "sns.countplot(x=test_predictions)\n",
    "plt.title(\"Prediction Distribution on Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Handle PassengerId: use if exists, else create index\n",
    "if \"PassengerId\" in test_df.columns:\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": test_predictions\n",
    "    })\n",
    "else:\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": range(1, len(test_predictions) + 1),\n",
    "        \"Survived\": test_predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"titanic_predictions.csv\", index=False)\n",
    "print(\"Submission file saved: titanic_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
